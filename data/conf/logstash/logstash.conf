input {
    file {
        type => "microsoft_ad"
        path => "/vagrant_data/idm/Microsoft - AD.log"
        start_position => "beginning"
#        codec => multiline {
#            negate => false
#            pattern => "^(<|([ ]*<))|[ ]*[a-zA-z0-9]*"
#            what => previous
#        }
    }
    file {
        type => "novell_edir"
        path => "/vagrant_data/idm/Novell - eDir.log"
        start_position => "beginning"
#        codec => multiline {
#            negate => false
#            pattern => "^(<|([ ]*<))|[ ]*[a-zA-z0-9]*"
#            what => previous
#        }
    }
    file {
        type => "novell_eos"
        path => "/vagrant_data/idm/Novell - EOS.log"
        start_position => "beginning"
#        codec => multiline {
#            negate => false
#            pattern => "^(<|([ ]*<))|[ ]*[a-zA-z0-9]*"
#            what => previous
#        }
    }
    file {
        type => "sun_ldap"
        path => "/vagrant_data/idm/Sun - LDAP.log"
        start_position => "beginning"
#        codec => multiline {
#            negate => false
#            pattern => "^(<|([ ]*<))|[ ]*[a-zA-z0-9]*"
#            what => previous
#        }
    }
}

filter {
    if [type] == "microsoft_ad" {
        grok {
            match => [ "message", "^\[%{DATE:date} %{TIME:time}\.%{INT:integer}\]:%{ACTIVE_DIRECTORY_TYPE}:%{GREEDYDATA:donnees}$" ]
            patterns_dir => "/vagrant_data/conf/pattern"
        }

        # Si le message est en erreur, on ne l'ajoute pas a l'index du jour !!!
        if ("_grokparsefailure" in [tags]) {
            ruby {
                code => "event.cancel"
            }
        }
        else {
            ruby {
                code => "event['my_timestamp']='20'.concat(event['date'][6..7]).
                                                concat('-').
                                                concat(event['date'][0..1]).
                                                concat('-').
                                                concat(event['date'][3..4]).
                                                concat(':').
                                                concat(event['time']).
                                                concat('.').
                                                concat(event['integer'])"
            }

            date {
                locale => en
                timezone => "Europe/Paris"
                match => [ "my_timestamp", "YYYY-MM-dd:HH:mm:ss.SSS" ]
            }

            mutate {
                replace => [ "message", "%{donnees}" ]
                remove_field => [ "donnees", "date", "time", "integer", "my_timestamp" ]
            }
        }
    }
    if [type] == "novell_edir" {
        grok {
            match => [ "message", "^\[%{DATE:date} %{TIME:time}\.%{INT:integer}\]:%{NOVELL_EDIR_TYPE}:%{GREEDYDATA:donnees}$" ]
            patterns_dir => "/vagrant_data/conf/pattern"
        }

        # Si le message est en erreur, on ne l'ajoute pas a l'index du jour !!!
        if ("_grokparsefailure" in [tags]) {
            ruby {
                code => "event.cancel"
            }
        }
        else {
            ruby {
                code => "event['my_timestamp']='20'.concat(event['date'][6..7]).
                                                concat('-').
                                                concat(event['date'][0..1]).
                                                concat('-').
                                                concat(event['date'][3..4]).
                                                concat(':').
                                                concat(event['time']).
                                                concat('.').
                                                concat(event['integer'])"
            }

            date {
                locale => en
                timezone => "Europe/Paris"
                match => [ "my_timestamp", "YYYY-MM-dd:HH:mm:ss.SSS" ]
            }

            mutate {
                replace => [ "message", "%{donnees}" ]
                remove_field => [ "donnees", "date", "time", "integer", "my_timestamp" ]
            }
        }
    }
    if [type] == "novell_eos" {
        grok {
            match => [ "message", "^\[%{DATE:date} %{TIME:time}\.%{INT:integer}\]:%{NOVELL_EOS_TYPE}:%{GREEDYDATA:donnees}$" ]
            patterns_dir => "/vagrant_data/conf/pattern"
        }

        # Si le message est en erreur, on ne l'ajoute pas a l'index du jour !!!
        if ("_grokparsefailure" in [tags]) {
            ruby {
                code => "event.cancel"
            }
        }
        else {
            ruby {
                code => "event['my_timestamp']='20'.concat(event['date'][6..7]).
                                                concat('-').
                                                concat(event['date'][0..1]).
                                                concat('-').
                                                concat(event['date'][3..4]).
                                                concat(':').
                                                concat(event['time']).
                                                concat('.').
                                                concat(event['integer'])"
            }

            date {
                locale => en
                timezone => "Europe/Paris"
                match => [ "my_timestamp", "YYYY-MM-dd:HH:mm:ss.SSS" ]
            }

            mutate {
                replace => [ "message", "%{donnees}" ]
                remove_field => [ "donnees", "date", "time", "integer", "my_timestamp" ]
            }
        }
    }
    if [type] == "sun_ldap" {
        grok {
            match => [ "message", "^\[%{DATE:date} %{TIME:time}\.%{INT:integer}\]:%{SUN_TYPE}:%{GREEDYDATA:donnees}$" ]
            patterns_dir => "/vagrant_data/conf/pattern"
        }

        # Si le message est en erreur, on ne l'ajoute pas a l'index du jour !!!
        if ("_grokparsefailure" in [tags]) {
            ruby {
                code => "event.cancel"
            }
        }
        else {
            ruby {
                code => "event['my_timestamp']='20'.concat(event['date'][6..7]).
                                                concat('-').
                                                concat(event['date'][0..1]).
                                                concat('-').
                                                concat(event['date'][3..4]).
                                                concat(':').
                                                concat(event['time']).
                                                concat('.').
                                                concat(event['integer'])"
            }

            date {
                locale => en
                timezone => "Europe/Paris"
                match => [ "my_timestamp", "YYYY-MM-dd:HH:mm:ss.SSS" ]
            }

            mutate {
                replace => [ "message", "%{donnees}" ]
                remove_field => [ "donnees", "date", "time", "integer", "my_timestamp" ]
            }
        }
    }
}

output {
    elasticsearch {
        host => localhost
        index => "logstash-poc-id"
    }

    if [type] == "microsoft_ad" {
        file {
            path => "/tmp/logstash_output_microsoft_ad.txt"
        }
    }
    else if [type] == "novell_eos" {
        file {
            path => "/tmp/logstash_output_novell_eos.txt"
        }
    }
    else if [type] == "novell_edir" {
        file {
            path => "/tmp/logstash_output_novell_edir.txt"
        }
    }
    else if [type] == "sun_ldap" {
        file {
            path => "/tmp/logstash_output_sun_ldap.txt"
        }
    }
    else {
        file {
            path => "/tmp/logstash_output_all.txt"
        }
    }
}
